{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speproject.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMfFmyYGguxwcX5tB+vajUA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PPb81IbNPnYT","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QPWmN9lP1x6","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WQ1uki2Q3d7","colab_type":"code","outputId":"023072ea-a2ae-443d-d78c-0bc8e7a77840","executionInfo":{"status":"ok","timestamp":1586874439361,"user_tz":-120,"elapsed":2218,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":139,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PZrnVGFJ-jwV","colab_type":"text"},"source":["**TEXT PROCESSING**"]},{"cell_type":"code","metadata":{"id":"cElljn2TRWvv","colab_type":"code","colab":{}},"source":["#get text input\n","path_to_file = \"drive/My Drive/Colab Notebooks/targetdw.txt\"\n","text = open(path_to_file, 'r').read() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQaR5b6hS1Vy","colab_type":"code","colab":{}},"source":["#get each unique character from the dataset\n","vocab = sorted(set(text)) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOaewzueS8UL","colab_type":"code","colab":{}},"source":["#assign a number to each character & create two dictionaries that can go from numeric index to character and character to numeric index\n","char_to_ind = {char: ind for ind, char in enumerate(vocab)} \n","ind_to_char = np.array(vocab) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9C1TI5PLTNPe","colab_type":"code","colab":{}},"source":["#encode all the text\n","encoded_txt = np.array([char_to_ind[c] for c in text]) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XAIxKdGW-Wht","colab_type":"text"},"source":["**CREATING BATCHES**"]},{"cell_type":"code","metadata":{"id":"tRrubyLUlbN_","colab_type":"code","colab":{}},"source":["seq_len = 200 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_qV_qzXns8W","colab_type":"code","colab":{}},"source":["#get the total number of seq in input txt\n","total_num_seq = len(text) // (seq_len + 1) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDqGtg-Ln5I8","colab_type":"code","colab":{}},"source":["#creating training seq\n","char_dataset = tf.data.Dataset.from_tensor_slices(encoded_txt) #convert txt vector into stream of character indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjG1Z5DnCBnH","colab_type":"code","colab":{}},"source":["sequences = char_dataset.batch(seq_len + 1, drop_remainder = True) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Mrx0lT0o-bZ","colab_type":"code","colab":{}},"source":["#create input text seq and target txt seq which is shifted one character forward\n","def create_seq_targets(seq):\n","  input_txt = seq[:-1] #Hello my nam\n","  target_txt = seq[1:] #ello my name\n","  return input_txt, target_txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdmxXY16CIZM","colab_type":"code","colab":{}},"source":["#group them as a tuple\n","dataset = sequences.map(create_seq_targets) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFhssKMRp7QD","colab_type":"code","outputId":"544f3787-c1d1-43a7-aae0-7bafcdf339e1","executionInfo":{"status":"ok","timestamp":1586874441805,"user_tz":-120,"elapsed":4375,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["#test input text and target text by printing the first seq\n","for input_txt, target_txt in dataset.take(1):\n","  print (input_txt.numpy())\n","  print(\"\".join(ind_to_char[input_txt.numpy()]))\n","  print('\\n')\n","  print(target_txt.numpy())\n","  print(\"\".join(ind_to_char[target_txt.numpy()]))"],"execution_count":150,"outputs":[{"output_type":"stream","text":["[14  0 49 62 67 67 58 71  1 46 54 64 58 72  1 27 65 65  0 95 29 61 58 56\n"," 64  2 96  0 46 61 58 71 58  1 76 54 72  1 72 54 73 62 72 59 54 56 73 62\n"," 68 67  1 62 67  1 46 74 71 65 68 74 60 61 96 72  1 75 68 62 56 58  1 54\n"," 72  1 61 58  1 66 68 75 58 57  0 61 62 72  1 70 74 58 58 67  1 62 67 73\n"," 68  1 69 68 72 62 73 62 68 67 11  1 34 58  1 61 54 57  1 61 62 72  1 68\n"," 69 69 68 67 58 67 73  1 68 67  1 73 61 58  1 71 74 67  0 67 68 76  9  1\n"," 54 67 57  1 75 58 71 78  1 72 68 68 67  1 73 61 58  1 76 61 62 73 58  1\n"," 64 62 67 60  1 76 68 74 65 57  1 55 58  1 56 68 71 67 58 71 58 57  1 54\n"," 67 57  0 56 68 66 69 65]\n","1\n","Winner Takes All\n","‘Check!’\n","There was satisfaction in Turlough’s voice as he moved\n","his queen into position. He had his opponent on the run\n","now, and very soon the white king would be cornered and\n","compl\n","\n","\n","[ 0 49 62 67 67 58 71  1 46 54 64 58 72  1 27 65 65  0 95 29 61 58 56 64\n","  2 96  0 46 61 58 71 58  1 76 54 72  1 72 54 73 62 72 59 54 56 73 62 68\n"," 67  1 62 67  1 46 74 71 65 68 74 60 61 96 72  1 75 68 62 56 58  1 54 72\n","  1 61 58  1 66 68 75 58 57  0 61 62 72  1 70 74 58 58 67  1 62 67 73 68\n","  1 69 68 72 62 73 62 68 67 11  1 34 58  1 61 54 57  1 61 62 72  1 68 69\n"," 69 68 67 58 67 73  1 68 67  1 73 61 58  1 71 74 67  0 67 68 76  9  1 54\n"," 67 57  1 75 58 71 78  1 72 68 68 67  1 73 61 58  1 76 61 62 73 58  1 64\n"," 62 67 60  1 76 68 74 65 57  1 55 58  1 56 68 71 67 58 71 58 57  1 54 67\n"," 57  0 56 68 66 69 65 58]\n","\n","Winner Takes All\n","‘Check!’\n","There was satisfaction in Turlough’s voice as he moved\n","his queen into position. He had his opponent on the run\n","now, and very soon the white king would be cornered and\n","comple\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LeCwAWXyuZPA","colab_type":"code","colab":{}},"source":["#generating training batches\n","batch_size = 64 \n","buffer_size = 10000\n","dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8uxj9WnCN7-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"01efcdc5-70fe-4619-fc67-4e2b6da00a50","executionInfo":{"status":"ok","timestamp":1586874441807,"user_tz":-120,"elapsed":4341,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}}},"source":["dataset"],"execution_count":152,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int64, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":152}]},{"cell_type":"markdown","metadata":{"id":"S3Bo6_KTCHyk","colab_type":"text"},"source":["we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text\n"]},{"cell_type":"markdown","metadata":{"id":"d7ASBh0tCcQq","colab_type":"text"},"source":["**CREATING THE MODEL**"]},{"cell_type":"code","metadata":{"id":"RXNF24GawG7I","colab_type":"code","colab":{}},"source":["vocab_size = len(vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NQjerthCl49","colab_type":"code","colab":{}},"source":["embed_dim = 74"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8h87oieXCz-s","colab_type":"code","colab":{}},"source":["rnn_neurons = 1024"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYTIj98WCdLl","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, GRU, Dense"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWakT80RC49_","colab_type":"code","colab":{}},"source":["from tensorflow.keras.losses import sparse_categorical_crossentropy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OG17GY3DjYF","colab_type":"code","colab":{}},"source":["#set up the loss function\n","def sparse_cat_loss(y_true, y_pred):\n","  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x68T1ac0JG7e","colab_type":"code","colab":{}},"source":["#create the model\n","def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n","    model = Sequential()\n","    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n","    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n","    # Final Dense Layer to Predict\n","    model.add(Dense(vocab_size))\n","    model.compile(optimizer='adam', loss=sparse_cat_loss) \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yyq3LkvKJ9pa","colab_type":"code","colab":{}},"source":["model = create_model(vocab_size=vocab_size,\n","                     embed_dim=embed_dim,\n","                     rnn_neurons=rnn_neurons,\n","                     batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJgkwxx9CqYx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"3baabb4b-bbd5-4cd6-eeb9-00dd6f369dff","executionInfo":{"status":"ok","timestamp":1586874442699,"user_tz":-120,"elapsed":5103,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}}},"source":["model.summary()"],"execution_count":161,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (64, None, 74)            7474      \n","_________________________________________________________________\n","gru_8 (GRU)                  (64, None, 1024)          3379200   \n","_________________________________________________________________\n","dense_8 (Dense)              (64, None, 101)           103525    \n","=================================================================\n","Total params: 3,490,199\n","Trainable params: 3,490,199\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"todI_BogKQcJ","colab_type":"code","colab":{}},"source":["#generate txt with the model without training to check if it works\n","for input_example_batch, target_example_batch in dataset.take(1):\n","  example_batch_predictions = model(input_example_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8rwiY5ZA7Se0","colab_type":"code","colab":{}},"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiPcxQjm7uLq","colab_type":"code","colab":{}},"source":["sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0QCk5Al8Ta3","colab_type":"code","outputId":"022d75e7-0e8f-4ca4-c547-4e743614eb8a","executionInfo":{"status":"ok","timestamp":1586874444856,"user_tz":-120,"elapsed":7184,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["ind_to_char[sampled_indices]"],"execution_count":165,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['E', 'n', 'v', '‡', 'b', '5', 'a', '4', '3', 'l', '1', 'w', 'z',\n","       'x', 'X', 'J', 'S', 'I', '6', ',', 'æ', 'K', 'Q', 'j', '2', 'g',\n","       'l', 'u', '/', '(', 'w', 'â', '—', 'æ', 'l', '?', '1', '/', '-',\n","       't', '“', '‘', 'é', \"'\", 'g', '2', 'S', 'm', 'V', '%', 'K', 'J',\n","       'Q', 'B', ')', ':', 'l', 'k', 'é', 'A', 'Z', 'è', ':', 'T', 'Y',\n","       'X', '?', '0', 'œ', 'o', 'f', 'B', 'I', '-', 'â', '-', '(', '2',\n","       'Q', 'm', '7', 'J', '=', 'T', 'd', '-', '1', 'X', 'z', 'j', '£',\n","       'G', '7', 'E', 'e', 'o', 'I', 'F', '“', '’', 'P', 'o', 'æ', 'ë',\n","       'V', '!', ')', 'Z', 'L', 'a', 'd', 'v', '/', 'æ', ' ', '£', 'h',\n","       'v', 'p', 'J', 'n', 'J', '2', 'é', 't', 'r', ' ', '†', 'g', '-',\n","       'Y', '(', '”', '3', 'n', '/', '1', 'è', '\"', '4', 'z', 'y', 't',\n","       'I', 'R', 'p', '–', 'H', '1', 'J', '8', 'x', 'O', 'h', 'z', 'w',\n","       '£', '\\n', '“', 'M', 'Q', \"'\", 'm', 'l', 'â', 'V', 'k', 'C', 'i',\n","       'o', 'M', 'D', '3', '?', 'u', 'ë', '½', '!', '‘', 'T', 'w', '“',\n","       'Q', 'H', '=', 'e', 'J', 'C', 'f', 'm', '.', 'i', '6', 'â', 'l',\n","       'G', 'x', '*', '2', 'ä'], dtype='<U1')"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"markdown","metadata":{"id":"q0tybc_Oel3Q","colab_type":"text"},"source":["**TRAINING THE MODEL**"]},{"cell_type":"code","metadata":{"id":"xrVpzPtF8anT","colab_type":"code","colab":{}},"source":["epochs = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SS4bTiqgF6_t","colab_type":"code","outputId":"a73b97a0-1dfa-4057-d967-876afc8c4179","executionInfo":{"status":"ok","timestamp":1586877306131,"user_tz":-120,"elapsed":1025185,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["model.fit(dataset, epochs=epochs)"],"execution_count":167,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1155/1155 [==============================] - 286s 247ms/step - loss: 1.8450\n","Epoch 2/10\n","1155/1155 [==============================] - 286s 248ms/step - loss: 1.2545\n","Epoch 3/10\n","1155/1155 [==============================] - 285s 247ms/step - loss: 1.1675\n","Epoch 4/10\n","1155/1155 [==============================] - 279s 241ms/step - loss: 1.1289\n","Epoch 5/10\n","1155/1155 [==============================] - 278s 241ms/step - loss: 1.1045\n","Epoch 6/10\n","1155/1155 [==============================] - 278s 240ms/step - loss: 1.0876\n","Epoch 7/10\n","1155/1155 [==============================] - 288s 249ms/step - loss: 1.0746\n","Epoch 8/10\n","1155/1155 [==============================] - 288s 249ms/step - loss: 1.0650\n","Epoch 9/10\n","1155/1155 [==============================] - 287s 249ms/step - loss: 1.0575\n","Epoch 10/10\n","1155/1155 [==============================] - 286s 248ms/step - loss: 1.0514\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f403bdd8ac8>"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"id":"qTu_YaBtQZwx","colab_type":"code","colab":{}},"source":["model.save('dw_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rwbQYseJe27L","colab_type":"text"},"source":["**GENERATING TEXT**"]},{"cell_type":"code","metadata":{"id":"XAKtpk0irejI","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import load_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDKCaiFQxe6Z","colab_type":"code","colab":{}},"source":["#create model\n","model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n","\n","#load trained weights\n","model.load_weights('dw_model.h5')\n","\n","#build model with a batch_size of 1\n","model.build(tf.TensorShape([1, None]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmoqcboDx_4D","colab_type":"code","colab":{}},"source":["def generate_txt(model, start_seed,gen_size=100,temp=1.0):\n","\n","  #number of characters to generate\n","  num_generate = gen_size\n","\n","  #vecotrizing the word to create txt from\n","  input_eval = [char_to_ind[s] for s in start_seed]\n","\n","  #expand to match batch format shape\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  #empty list to hold resulting generated text\n","  txt_generated = []\n"," \n","  temperature = temp\n","\n","  #clears hidden layer of the model\n","  model.reset_states()\n","\n","  for i in range(num_generate):\n","\n","      #generate predictions\n","      predictions = model(input_eval)\n","\n","      #remove the batch shape dimension\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      #use a categorical disitribution to select the next character\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      #pass the predicted character for the next input\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      #transform back to character letter\n","      txt_generated.append(ind_to_char[predicted_id])\n","\n","  return (start_seed + ''.join(txt_generated))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TyVJCZnByR6n","colab_type":"code","outputId":"8837e98a-543a-4aee-e96b-5b3bc8c946cb","executionInfo":{"status":"ok","timestamp":1586879139234,"user_tz":-120,"elapsed":7441,"user":{"displayName":"Hélène Picard","photoUrl":"","userId":"00202636490764260252"}},"colab":{"base_uri":"https://localhost:8080/","height":422}},"source":["print(generate_txt(model,\"Doctor\",gen_size=1000))"],"execution_count":185,"outputs":[{"output_type":"stream","text":["Doctor.\n","‘What? I dinned that Swordsman’s alcove rose out of the\n","castle. Herembirs the wounded outwards flowing dials.\n","Maren’s house was flat and so after they? Satisfied?T and\n","find light in a long and search.\n","Lowe lay somb roughly colonists’ spy... \n","2\n","The Doctor’s habbed for\n","she had encountered. The Doctor’s eyes held bewildered.\n","Collins followed.\n","Two more questers on the edge of the Galaxt Was\n","the thought of settless happening, and saw that two set\n","wouldn’t lost – not in yearsh of an enormous tall man in\n","Boluce’ and she was hunched away—for the first couthing he could\n","see. Leela held out his shoulder and staggered on, ‘and\n","the man was planning to. Fasters on Earth some owive in there... Here, then it\n","would see now. You may have done so much fully like rather\n","more likely.’\n","‘I am in Solos and I got the signal affected our race.\n","Ran sprival over the planetary inhabitants, I seem—deceiving\n","maskem,’ snarled Gomer.\n","The conflict was the Doctor to tell me about Hildred. I\n","must go and find the man i\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F4GPwZetzGdw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOMbmBZ9yaba","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}